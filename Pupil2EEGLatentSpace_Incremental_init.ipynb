{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PhNb0uOzc8j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import split_dataset\n",
        "import scipy.io\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtRrOJG5zeAQ",
        "outputId": "256aacfb-74ce-426c-ebe6-cec7ad76cce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load data**"
      ],
      "metadata": {
        "id": "1kTxT6CKrXvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/'\n",
        "\n",
        "stim_pupil = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/4444/stim_pupil.npy')\n",
        "spon_pupil = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/4444/spon_pupil.npy')\n",
        "\n",
        "stim_latent_space = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/4444/stim_latent_space.npy')\n",
        "spon_latent_space = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/4444/spon_latent_space.npy')\n",
        "\n",
        "# stim_pupil = stim_pupil.T  # Shape: (600, 900)\n",
        "# spon_pupil = spon_pupil.T  # Shape: (600, 900)\n",
        "\n",
        "stim_labels_list = [stim_latent_space[:, :, i] for i in range(6)]\n",
        "spon_labels_list = [spon_latent_space[:, :, i] for i in range(6)]\n",
        "\n",
        "# scaler_stim = StandardScaler()\n",
        "# scaler_spon = StandardScaler()\n",
        "# stim_pupil = scaler_stim.fit_transform(stim_pupil.reshape(-1, stim_pupil.shape[-1])).reshape(stim_pupil.shape)\n",
        "# spon_pupil = scaler_spon.fit_transform(spon_pupil.reshape(-1, spon_pupil.shape[-1])).reshape(spon_pupil.shape)\n",
        "\n",
        "# scaler_stim_labels = [StandardScaler().fit(label) for label in stim_labels_list]\n",
        "# scaler_spon_labels = [StandardScaler().fit(label) for label in spon_labels_list]\n",
        "# stim_labels_list = [scaler.transform(label) for scaler, label in zip(scaler_stim_labels, stim_labels_list)]\n",
        "# spon_labels_list = [scaler.transform(label) for scaler, label in zip(scaler_spon_labels, spon_labels_list)]\n",
        "\n",
        "# comment the following lines when not running the SUBJECT-CROSSVALIDATION#############\n",
        "stim_animal_ids = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/raw pupil + dict (animal IDs)/stim_eeg_dict.npy')\n",
        "spon_animal_ids = np.load('/content/drive/My Drive/Response Inhibition Project/2023EvanIEEE/IOP/data/raw pupil + dict (animal IDs)/spon_eeg_dict.npy')\n",
        "print(\"Shape of stim_dict:\", stim_animal_ids.shape)\n",
        "print(\"Shape of spon_dict:\", spon_animal_ids.shape)\n",
        "#######################################################################################\n",
        "\n",
        "print(\"Shape of stim_pupil:\", stim_pupil.shape)\n",
        "print(\"Shape of spon_pupil:\", spon_pupil.shape)\n",
        "print(\"Shapes of stim_labels_list:\", [label.shape for label in stim_labels_list])\n",
        "print(\"Shapes of spon_labels_list:\", [label.shape for label in spon_labels_list])"
      ],
      "metadata": {
        "id": "ewEiA6Q7zkNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define functions**"
      ],
      "metadata": {
        "id": "JyY0j4yWrcI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(10))  # Output layer with 10 points\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def compute_metric(y_true, y_pred):\n",
        "    return np.array([mean_squared_error(y_true[i], y_pred[i]) for i in range(len(y_true))])\n",
        "\n",
        "class PrintMSECallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_loss = logs.get('loss')\n",
        "        val_loss = logs.get('val_loss')\n",
        "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "def train_with_combinations(data, labels, animal_ids, k, m):\n",
        "    unique_animals = np.unique(animal_ids)\n",
        "    best_model = None\n",
        "    min_val_loss = float('inf')\n",
        "    history_best = None\n",
        "\n",
        "    for train_animals in combinations(unique_animals, k-1):\n",
        "\n",
        "        train_indices = np.where(np.isin(animal_ids, train_animals))[0]\n",
        "        test_indices = np.where(~np.isin(animal_ids, train_animals))[0]\n",
        "\n",
        "        X_train, y_train = data[train_indices], labels[train_indices]\n",
        "        X_val, y_val = data[test_indices], labels[test_indices]\n",
        "\n",
        "        kf = KFold(n_splits=m)\n",
        "        for fold_idx, (train_index, test_index) in kf.split(X_train):\n",
        "            print(f\"Pretraining step on {train_animals} ...  fold {fold_idx}\")\n",
        "            X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
        "            y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
        "\n",
        "            model = build_model((X_train_fold.shape[1],))\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "            print_mse_callback = PrintMSECallback()\n",
        "            history = model.fit(X_train_fold, y_train_fold, batch_size=32, epochs=100, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping, print_mse_callback], verbose=0, shuffle=True)\n",
        "\n",
        "            val_loss = min(history.history['val_loss'])\n",
        "            if val_loss < min_val_loss:\n",
        "                min_val_loss = val_loss\n",
        "                best_model = model\n",
        "                history_best = history.history\n",
        "\n",
        "    print(f\"Best model-0 found! Proceeding to fine-tuning ...\")\n",
        "\n",
        "    return best_model, history_best, min_val_loss\n",
        "\n",
        "def fine_tune_and_test(animal, best_model, X_train, y_train, m):\n",
        "    kf = KFold(n_splits=m)\n",
        "    min_mse = float('inf')\n",
        "    best_fold_history = None\n",
        "    all_mse_vectors = []\n",
        "\n",
        "    for fold_idx, (train_index, test_index) in kf.split(X_train):\n",
        "        print(f\"Fine-tuning step on {animal} ... fold {fold_idx}\")\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "        print_mse_callback = PrintMSECallback()\n",
        "        history = best_model.fit(X_train_fold, y_train_fold, batch_size=32, epochs=100, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping, print_mse_callback], verbose=1, shuffle=True)\n",
        "\n",
        "        val_loss = min(history.history['val_loss'])\n",
        "        y_pred = best_model.predict(X_val_fold)\n",
        "        mse_vector = compute_metric(y_val_fold, y_pred)\n",
        "\n",
        "        if np.mean(mse_vector) < min_mse:\n",
        "            min_mse = np.mean(mse_vector)\n",
        "            best_fold_history = history.history\n",
        "\n",
        "        all_mse_vectors.extend(mse_vector)\n",
        "\n",
        "    print(f\"Best model-x found!\")\n",
        "\n",
        "    return min_mse, best_fold_history, all_mse_vectors\n",
        "\n",
        "def cross_validate_animals(data, labels, animal_ids, k, m0, m1):\n",
        "    unique_animals = np.unique(animal_ids)\n",
        "    results = {}\n",
        "\n",
        "    for animal in unique_animals:\n",
        "        print(f\"Processing animal {animal} as the test animal...\")\n",
        "        train_indices = np.where(animal_ids != animal)[0]\n",
        "        test_indices = np.where(animal_ids == animal)[0]\n",
        "\n",
        "\n",
        "        X_train, y_train = data[train_indices], labels[train_indices] # combinations of k-1 animals -> best pretrained model (Mdl-0)\n",
        "        best_model, history_best, val_loss_step1 = train_with_combinations(X_train, y_train, animal_ids[train_indices], k, m0)\n",
        "\n",
        "        X_train_ft, y_train_ft = data[test_indices], labels[test_indices] # left-out 1 animal -> best fine-tuned model (Mdl-x)\n",
        "        val_loss_step2, best_fold_history, mse_vector = fine_tune_and_test(animal, best_model, X_train_ft, y_train_ft, m1)\n",
        "\n",
        "        results[f'animal_{animal}'] = {\n",
        "            'History_BestMdl-0': history_best,\n",
        "            'AverageLoss_BestMdl-0': val_loss_step1,\n",
        "            'History_BestMdl-x': best_fold_history,\n",
        "            'AverageLoss_BestMdl-x': val_loss_step2,\n",
        "            'Weights_BestMdl-x': best_model.get_weights(),\n",
        "            'TrialMSE_Mdl-x': mse_vector\n",
        "        } # lumped result saving\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "hUMeGdu8zeCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run and save**"
      ],
      "metadata": {
        "id": "0A6AXqg1rg2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run cross-validation and save results\n",
        "k = 12 # number of total animals\n",
        "m0 = 5 # number of folds used in pretraining\n",
        "m1 = 5 # number of folds used in fine-tuning\n",
        "for i, (stim_labels, spon_labels) in enumerate(zip(stim_labels_list, spon_labels_list), 1):\n",
        "    stim_results = cross_validate_animals(stim_pupil, stim_labels, stim_animal_ids, k, m0, m1)\n",
        "    scipy.io.savemat(f'stim_results_{i}.mat', {f'stim_results_{i}': stim_results})\n",
        "\n",
        "    print(f\"Results for stim_pupil -> stim_latent_space_{i} saved.\")\n",
        "\n",
        "    spon_results = cross_validate_animals(spon_pupil, spon_labels, spon_animal_ids, k, m0, m1)\n",
        "    scipy.io.savemat(f'spon_results_{i}.mat', {f'spon_results_{i}': spon_results})\n",
        "\n",
        "    print(f\"Results for spon_pupil -> spon_latent_space_{i} saved.\")"
      ],
      "metadata": {
        "id": "gS6hrFCXz0ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4iwnC7mCe95"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}